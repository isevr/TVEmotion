{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr No.</th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>461</td>\n",
       "      <td>You tell them to wait!</td>\n",
       "      <td>Ross</td>\n",
       "      <td>anger</td>\n",
       "      <td>negative</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>00:21:11,937</td>\n",
       "      <td>00:21:14,230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>778</td>\n",
       "      <td>Oh, fine! Take his side!</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>anger</td>\n",
       "      <td>negative</td>\n",
       "      <td>72</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>00:12:13,774</td>\n",
       "      <td>00:12:16,234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>451</td>\n",
       "      <td>Okay Joey, first of all Kash Ford is not peopl...</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>anger</td>\n",
       "      <td>negative</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>00:06:56,874</td>\n",
       "      <td>00:06:58,750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>792</td>\n",
       "      <td>Seriously. What?!</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>surprise</td>\n",
       "      <td>negative</td>\n",
       "      <td>74</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>00:10:18,909</td>\n",
       "      <td>00:10:20,827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>861</td>\n",
       "      <td>No. Have you seen David?</td>\n",
       "      <td>Max</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>00:12:04,807</td>\n",
       "      <td>00:12:06,683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>771</td>\n",
       "      <td>Yeah, well, y'know maybe you just need to try ...</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>anger</td>\n",
       "      <td>negative</td>\n",
       "      <td>72</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>00:11:43,911</td>\n",
       "      <td>00:11:47,914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>105</td>\n",
       "      <td>It's a witness not a perp. And no one talks li...</td>\n",
       "      <td>Gary</td>\n",
       "      <td>anger</td>\n",
       "      <td>negative</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0:07:07,593</td>\n",
       "      <td>0:07:10,096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>815</td>\n",
       "      <td>So it's kinda like, you're, you know.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>76</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>00:17:00,769</td>\n",
       "      <td>00:17:08,860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>445</td>\n",
       "      <td>I thought I was a complete idiot.</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>surprise</td>\n",
       "      <td>positive</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>00:06:37,605</td>\n",
       "      <td>00:06:40,857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>208</td>\n",
       "      <td>Have you seen Chandler?!</td>\n",
       "      <td>Monica</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>0:16:18,519</td>\n",
       "      <td>0:16:19,401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sr No.                                          Utterance   Speaker  \\\n",
       "0       461                             You tell them to wait!      Ross   \n",
       "1       778                           Oh, fine! Take his side!    Phoebe   \n",
       "2       451  Okay Joey, first of all Kash Ford is not peopl...    Rachel   \n",
       "3       792                                  Seriously. What?!    Rachel   \n",
       "4       861                           No. Have you seen David?       Max   \n",
       "..      ...                                                ...       ...   \n",
       "217     771  Yeah, well, y'know maybe you just need to try ...    Phoebe   \n",
       "218     105  It's a witness not a perp. And no one talks li...      Gary   \n",
       "219     815              So it's kinda like, you're, you know.  Chandler   \n",
       "220     445                  I thought I was a complete idiot.    Rachel   \n",
       "221     208                           Have you seen Chandler?!    Monica   \n",
       "\n",
       "      Emotion Sentiment  Dialogue_ID  Utterance_ID  Season  Episode  \\\n",
       "0       anger  negative           42             1       5        1   \n",
       "1       anger  negative           72            18       5       11   \n",
       "2       anger  negative           40             6       8        5   \n",
       "3    surprise  negative           74            10       8        3   \n",
       "4     neutral   neutral           80             1       1       10   \n",
       "..        ...       ...          ...           ...     ...      ...   \n",
       "217     anger  negative           72            11       5       11   \n",
       "218     anger  negative           10             4       5       20   \n",
       "219   neutral   neutral           76            12       3        1   \n",
       "220  surprise  positive           40             0       8        5   \n",
       "221   neutral   neutral           18             2       6       22   \n",
       "\n",
       "        StartTime       EndTime  \n",
       "0    00:21:11,937  00:21:14,230  \n",
       "1    00:12:13,774  00:12:16,234  \n",
       "2    00:06:56,874  00:06:58,750  \n",
       "3    00:10:18,909  00:10:20,827  \n",
       "4    00:12:04,807  00:12:06,683  \n",
       "..            ...           ...  \n",
       "217  00:11:43,911  00:11:47,914  \n",
       "218   0:07:07,593   0:07:10,096  \n",
       "219  00:17:00,769  00:17:08,860  \n",
       "220  00:06:37,605  00:06:40,857  \n",
       "221   0:16:18,519   0:16:19,401  \n",
       "\n",
       "[222 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('MELD.Raw/dev_sent_emo.csv',encoding='utf-8')\n",
    "df['Utterance'] = df.Utterance.str.replace('',\"'\")\n",
    "# df['gender'] = df.Speaker.apply(lambda x: 'male' if x == 'Ross' or x == 'Joey' or x == 'Chandler' else 'female')\n",
    "df = df.sample(frac=0.2,ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    t = text.lower()\n",
    "    t = re.sub('\\d+',r'',t)\n",
    "    t = re.sub(r'\\W+',r' ',t)\n",
    "    return t\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "\n",
    "df['prepro'] = [' '.join([lemmatizer.lemmatize(preprocess(txt))])\n",
    "                 .strip() for txt in df['Utterance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(categories=[df.Emotion.unique()])\n",
    "labels = ohe.fit_transform(df.Emotion.to_numpy().reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "13/13 [==============================] - 67s 3s/step - loss: 1.7582 - accuracy: 0.3413\n",
      "Epoch 2/3\n",
      "13/13 [==============================] - 40s 3s/step - loss: 1.5708 - accuracy: 0.4423\n",
      "Epoch 3/3\n",
      "13/13 [==============================] - 39s 3s/step - loss: 1.4293 - accuracy: 0.4808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bd146765f0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification, TFBertModel\n",
    "import numpy as np\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = TFBertForSequenceClassification.from_pretrained(model_name, num_labels=7)\n",
    "\n",
    "# Prepare your dataset for text classification\n",
    "train_texts = list(df.prepro.values)\n",
    "train_labels = list(labels)\n",
    "\n",
    "# Tokenize input texts\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "\n",
    "# Convert labels to tensors\n",
    "train_labels = tf.convert_to_tensor(train_labels)\n",
    "\n",
    "train_inputs = {\n",
    "    'input_ids': np.array(train_encodings['input_ids']),\n",
    "    'token_type_ids': np.array(train_encodings['token_type_ids']),\n",
    "    'attention_mask': np.array(train_encodings['attention_mask'])\n",
    "}\n",
    "\n",
    "# Create TensorFlow Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    train_inputs,\n",
    "    train_labels\n",
    ")).shuffle(len(train_inputs)).batch(16,drop_remainder=True)  # Adjust batch size as needed\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# Fine-tune the model\n",
    "model.fit(train_dataset, epochs=3, verbose=1)  # Adjust epochs as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[ 101, 1045, 2572, 6517,  102]])>, 'token_type_ids': <tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[0, 0, 0, 0, 0]])>, 'attention_mask': <tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[1, 1, 1, 1, 1]])>}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blue = tokenizer('i am sad',return_tensors='tf')\n",
    "blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFSequenceClassifierOutput(loss=None, logits=<tf.Tensor: shape=(1, 7), dtype=float32, numpy=\n",
       "array([[ 0.26373643, -0.0307746 ,  1.4964006 ,  0.60248244, -1.3415707 ,\n",
       "        -0.9906973 , -0.2134671 ]], dtype=float32)>, hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model(blue)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
