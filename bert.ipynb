{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr No.</th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>461</td>\n",
       "      <td>You tell them to wait!</td>\n",
       "      <td>Ross</td>\n",
       "      <td>anger</td>\n",
       "      <td>negative</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>00:21:11,937</td>\n",
       "      <td>00:21:14,230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>778</td>\n",
       "      <td>Oh, fine! Take his side!</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>anger</td>\n",
       "      <td>negative</td>\n",
       "      <td>72</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>00:12:13,774</td>\n",
       "      <td>00:12:16,234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>451</td>\n",
       "      <td>Okay Joey, first of all Kash Ford is not peopl...</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>anger</td>\n",
       "      <td>negative</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>00:06:56,874</td>\n",
       "      <td>00:06:58,750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>792</td>\n",
       "      <td>Seriously. What?!</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>surprise</td>\n",
       "      <td>negative</td>\n",
       "      <td>74</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>00:10:18,909</td>\n",
       "      <td>00:10:20,827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>861</td>\n",
       "      <td>No. Have you seen David?</td>\n",
       "      <td>Max</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>00:12:04,807</td>\n",
       "      <td>00:12:06,683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>771</td>\n",
       "      <td>Yeah, well, y'know maybe you just need to try ...</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>anger</td>\n",
       "      <td>negative</td>\n",
       "      <td>72</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>00:11:43,911</td>\n",
       "      <td>00:11:47,914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>105</td>\n",
       "      <td>It's a witness not a perp. And no one talks li...</td>\n",
       "      <td>Gary</td>\n",
       "      <td>anger</td>\n",
       "      <td>negative</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0:07:07,593</td>\n",
       "      <td>0:07:10,096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>815</td>\n",
       "      <td>So it's kinda like, you're, you know.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>76</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>00:17:00,769</td>\n",
       "      <td>00:17:08,860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>445</td>\n",
       "      <td>I thought I was a complete idiot.</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>surprise</td>\n",
       "      <td>positive</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>00:06:37,605</td>\n",
       "      <td>00:06:40,857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>208</td>\n",
       "      <td>Have you seen Chandler?!</td>\n",
       "      <td>Monica</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>0:16:18,519</td>\n",
       "      <td>0:16:19,401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sr No.                                          Utterance   Speaker  \\\n",
       "0       461                             You tell them to wait!      Ross   \n",
       "1       778                           Oh, fine! Take his side!    Phoebe   \n",
       "2       451  Okay Joey, first of all Kash Ford is not peopl...    Rachel   \n",
       "3       792                                  Seriously. What?!    Rachel   \n",
       "4       861                           No. Have you seen David?       Max   \n",
       "..      ...                                                ...       ...   \n",
       "217     771  Yeah, well, y'know maybe you just need to try ...    Phoebe   \n",
       "218     105  It's a witness not a perp. And no one talks li...      Gary   \n",
       "219     815              So it's kinda like, you're, you know.  Chandler   \n",
       "220     445                  I thought I was a complete idiot.    Rachel   \n",
       "221     208                           Have you seen Chandler?!    Monica   \n",
       "\n",
       "      Emotion Sentiment  Dialogue_ID  Utterance_ID  Season  Episode  \\\n",
       "0       anger  negative           42             1       5        1   \n",
       "1       anger  negative           72            18       5       11   \n",
       "2       anger  negative           40             6       8        5   \n",
       "3    surprise  negative           74            10       8        3   \n",
       "4     neutral   neutral           80             1       1       10   \n",
       "..        ...       ...          ...           ...     ...      ...   \n",
       "217     anger  negative           72            11       5       11   \n",
       "218     anger  negative           10             4       5       20   \n",
       "219   neutral   neutral           76            12       3        1   \n",
       "220  surprise  positive           40             0       8        5   \n",
       "221   neutral   neutral           18             2       6       22   \n",
       "\n",
       "        StartTime       EndTime  \n",
       "0    00:21:11,937  00:21:14,230  \n",
       "1    00:12:13,774  00:12:16,234  \n",
       "2    00:06:56,874  00:06:58,750  \n",
       "3    00:10:18,909  00:10:20,827  \n",
       "4    00:12:04,807  00:12:06,683  \n",
       "..            ...           ...  \n",
       "217  00:11:43,911  00:11:47,914  \n",
       "218   0:07:07,593   0:07:10,096  \n",
       "219  00:17:00,769  00:17:08,860  \n",
       "220  00:06:37,605  00:06:40,857  \n",
       "221   0:16:18,519   0:16:19,401  \n",
       "\n",
       "[222 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('MELD.Raw/dev_sent_emo.csv',encoding='utf-8')\n",
    "df['Utterance'] = df.Utterance.str.replace('',\"'\")\n",
    "# df['gender'] = df.Speaker.apply(lambda x: 'male' if x == 'Ross' or x == 'Joey' or x == 'Chandler' else 'female')\n",
    "df = df.sample(frac=0.2,ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    t = text.lower()\n",
    "    t = re.sub('\\d+',r'',t)\n",
    "    t = re.sub(r'\\W+',r' ',t)\n",
    "    return t\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "\n",
    "df['prepro'] = [' '.join([lemmatizer.lemmatize(preprocess(txt))])\n",
    "                 .strip() for txt in df['Utterance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(categories=[df.Emotion.unique()])\n",
    "labels = ohe.fit_transform(df.Emotion.to_numpy().reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "13/13 [==============================] - 47s 2s/step - loss: 1.8082 - accuracy: 0.3317\n",
      "Epoch 2/3\n",
      "13/13 [==============================] - 29s 2s/step - loss: 1.4398 - accuracy: 0.4423\n",
      "Epoch 3/3\n",
      "13/13 [==============================] - 29s 2s/step - loss: 1.2264 - accuracy: 0.5577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bdc0260040>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification, TFBertModel\n",
    "import numpy as np\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = TFBertModel.from_pretrained(model_name)\n",
    "\n",
    "input_ids = tf.keras.Input(shape=(None,), dtype=tf.int32, name='input_ids')\n",
    "token_type_ids = tf.keras.Input(shape=(None,), dtype=tf.int32, name='token_type_ids')\n",
    "attention_mask = tf.keras.Input(shape=(None,), dtype=tf.int32, name='attention_mask')\n",
    "\n",
    "bert_outputs = model(\n",
    "    input_ids=input_ids,\n",
    "    token_type_ids=token_type_ids,\n",
    "    attention_mask=attention_mask\n",
    ")\n",
    "\n",
    "pooled_output = bert_outputs.pooler_output\n",
    "dense_layer = tf.keras.layers.Dense(256, activation='relu')(pooled_output)\n",
    "output_layer = tf.keras.layers.Dense(7, activation='softmax')(dense_layer)\n",
    "\n",
    "\n",
    "custom_model = tf.keras.Model(\n",
    "    inputs=[input_ids, token_type_ids, attention_mask],\n",
    "    outputs=output_layer\n",
    ")\n",
    "\n",
    "\n",
    "# Prepare dataset for text classification\n",
    "train_texts = list(df.prepro.values)\n",
    "train_labels = list(labels)\n",
    "\n",
    "# Tokenize input texts\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "\n",
    "# Convert labels to tensors\n",
    "train_labels = tf.convert_to_tensor(train_labels)\n",
    "\n",
    "train_inputs = {\n",
    "    'input_ids': np.array(train_encodings['input_ids']),\n",
    "    'token_type_ids': np.array(train_encodings['token_type_ids']),\n",
    "    'attention_mask': np.array(train_encodings['attention_mask'])\n",
    "}\n",
    "\n",
    "# Create TensorFlow Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    train_inputs,\n",
    "    train_labels\n",
    ")).shuffle(len(train_inputs)).batch(16,drop_remainder=True)  # Adjust batch size as needed\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "# Compile the model\n",
    "custom_model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# Fine-tune the model\n",
    "custom_model.fit(train_dataset, epochs=3, verbose=1)  # Adjust epochs as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 31s 2s/step - loss: 0.9785 - accuracy: 0.6827\n",
      "Epoch 2/3\n",
      "13/13 [==============================] - 31s 2s/step - loss: 0.7846 - accuracy: 0.7692\n",
      "Epoch 3/3\n",
      "13/13 [==============================] - 31s 2s/step - loss: 0.6740 - accuracy: 0.7981\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "(1, 6, 768)\n"
     ]
    }
   ],
   "source": [
    "# ... (Your existing code remains the same)\n",
    "\n",
    "# Fine-tune the model\n",
    "custom_model.fit(train_dataset, epochs=3, verbose=1)  # Adjust epochs as needed\n",
    "\n",
    "# Extract embeddings from the model\n",
    "embeddings_model = tf.keras.Model(inputs=custom_model.input, outputs=bert_outputs.last_hidden_state)\n",
    "\n",
    "# Prepare data for inference\n",
    "test_texts = [\"Your test sentences here\"]\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True)\n",
    "\n",
    "# Convert inputs to tensors\n",
    "test_inputs = {\n",
    "    'input_ids': np.array(test_encodings['input_ids']),\n",
    "    'token_type_ids': np.array(test_encodings['token_type_ids']),\n",
    "    'attention_mask': np.array(test_encodings['attention_mask'])\n",
    "}\n",
    "\n",
    "# Get embeddings for test data\n",
    "embeddings = embeddings_model.predict(test_inputs)\n",
    "\n",
    "# 'embeddings' now contains the embeddings for the test data\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[ 101, 1045, 2572, 6517,  102]])>, 'token_type_ids': <tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[0, 0, 0, 0, 0]])>, 'attention_mask': <tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[1, 1, 1, 1, 1]])>}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blue = tokenizer('i am sad',return_tensors='tf')\n",
    "blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.13594277, 0.08063605, 0.47514027, 0.18977657, 0.01977132,\n",
       "        0.03838995, 0.06034305]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = custom_model.predict([blue['input_ids'],blue['token_type_ids'],blue['attention_mask']])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['last_hidden_state', 'pooler_output'])\n",
      "(5, 4, 768)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "# Load fine-tuned BERT model\n",
    "model_name = 'bert-base-uncased'  # or your fine-tuned model name\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "amodel = TFBertModel.from_pretrained(model_name)\n",
    "\n",
    "# Your dataset sentences\n",
    "sentences = df.prepro.values\n",
    "\n",
    "# Tokenize the sentences\n",
    "tokenized_inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors='tf')\n",
    "\n",
    "# Get embeddings\n",
    "outputs = amodel(tokenized_inputs)\n",
    "hidden_states = outputs[0]  # Extract hidden states from the output tuple\n",
    "\n",
    "# Print keys in the outputs object\n",
    "print(outputs.keys())\n",
    "\n",
    "# Check the shape of hidden states\n",
    "print(hidden_states.shape)  # Print shape of hidden states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=<tf.Tensor: shape=(1, 5, 768), dtype=float32, numpy=\n",
       "array([[[-0.19910356,  0.538442  , -0.220623  , ...,  0.01834938,\n",
       "          0.32222158,  0.2692385 ],\n",
       "        [-0.57449394,  0.39249668, -0.5139347 , ...,  0.120591  ,\n",
       "          0.809383  ,  0.12798725],\n",
       "        [-0.77094674,  0.33647695, -0.1416466 , ...,  0.23776443,\n",
       "          0.29806218,  0.23093735],\n",
       "        [-1.0086286 ,  0.46211925, -0.00540426, ...,  0.67257756,\n",
       "          0.18979183, -0.22161974],\n",
       "        [ 0.6236303 ,  0.16630654, -0.37921596, ..., -0.03854161,\n",
       "         -0.4813545 , -0.4720742 ]]], dtype=float32)>, pooler_output=<tf.Tensor: shape=(1, 768), dtype=float32, numpy=\n",
       "array([[-8.91511977e-01, -3.56628299e-01, -2.96447903e-01,\n",
       "         7.63155341e-01,  6.84296596e-04, -5.61037362e-02,\n",
       "         8.69579017e-01,  2.51043111e-01, -3.83736402e-01,\n",
       "        -9.99966323e-01,  4.73340973e-03,  8.46770823e-01,\n",
       "         9.84883368e-01,  1.14933394e-01,  9.44804251e-01,\n",
       "        -6.61679268e-01, -3.03593516e-01, -5.67945838e-01,\n",
       "         3.14184129e-01, -7.87831008e-01,  6.49671495e-01,\n",
       "         9.95117426e-01,  4.04940307e-01,  2.08288684e-01,\n",
       "         3.72644603e-01,  9.37965333e-01, -6.37502015e-01,\n",
       "         9.23012257e-01,  9.63773310e-01,  7.11103201e-01,\n",
       "        -6.81378365e-01,  2.54280362e-02, -9.89836812e-01,\n",
       "        -4.77147363e-02, -4.87876177e-01, -9.93158758e-01,\n",
       "         2.34406605e-01, -7.38418281e-01,  1.20762415e-01,\n",
       "         1.94960952e-01, -9.00053203e-01,  2.14949846e-01,\n",
       "         9.99798179e-01, -1.53040171e-01,  1.77726969e-01,\n",
       "        -1.88352600e-01, -9.99998510e-01,  1.81271031e-01,\n",
       "        -9.06962514e-01,  4.65176076e-01,  4.29320723e-01,\n",
       "         2.94183463e-01,  1.57786414e-01,  4.16578650e-01,\n",
       "         4.01634157e-01,  7.98725784e-02, -1.89363465e-01,\n",
       "         7.50069991e-02, -1.56345427e-01, -5.19821227e-01,\n",
       "        -5.68516910e-01,  3.75048608e-01, -4.41958219e-01,\n",
       "        -9.10294592e-01,  4.69806999e-01,  5.56239486e-02,\n",
       "         1.08923176e-02, -1.54584244e-01,  3.02904360e-02,\n",
       "        -2.14522988e-01,  8.58243644e-01,  1.63001046e-01,\n",
       "         2.84404457e-01, -8.10710311e-01,  9.03206989e-02,\n",
       "         1.13249347e-01, -6.20193958e-01,  1.00000000e+00,\n",
       "        -5.54892421e-01, -9.80851054e-01,  3.13149810e-01,\n",
       "         1.49792492e-01,  5.03998280e-01,  3.48530889e-01,\n",
       "        -2.94880599e-01, -1.00000000e+00,  3.62936258e-01,\n",
       "        -2.57069361e-04, -9.90124941e-01,  9.99467671e-02,\n",
       "         4.43731636e-01, -1.21287495e-01, -2.20831543e-01,\n",
       "         5.76801717e-01, -2.51941085e-01, -3.14842761e-01,\n",
       "        -2.41765365e-01, -2.49485448e-01, -1.50147572e-01,\n",
       "        -1.50630876e-01,  3.86404851e-03, -1.39560729e-01,\n",
       "        -1.11373715e-01, -2.81504303e-01,  1.56014323e-01,\n",
       "        -4.18573886e-01, -5.89852870e-01,  1.42376691e-01,\n",
       "        -1.35248497e-01,  6.70168519e-01,  4.00034487e-01,\n",
       "        -2.78250247e-01,  3.00346553e-01, -9.54961717e-01,\n",
       "         6.35519207e-01, -3.09611499e-01, -9.86238182e-01,\n",
       "        -5.49963653e-01, -9.89113212e-01,  7.03366935e-01,\n",
       "         6.90457374e-02, -1.38322204e-01,  9.71239388e-01,\n",
       "         3.04035038e-01,  2.45754346e-01,  7.58967325e-02,\n",
       "        -5.61542034e-01, -1.00000000e+00, -6.21078312e-01,\n",
       "        -3.04033607e-01,  2.11807013e-01, -1.03027761e-01,\n",
       "        -9.83859241e-01, -9.52708066e-01,  5.32845378e-01,\n",
       "         9.47050989e-01,  7.63385221e-02,  9.99498725e-01,\n",
       "        -2.25967124e-01,  9.56508219e-01,  8.99180421e-04,\n",
       "        -2.37090051e-01,  2.46389195e-01, -4.12278414e-01,\n",
       "         4.46796954e-01,  2.35450074e-01, -6.96334600e-01,\n",
       "         1.68292925e-01, -6.30963668e-02,  2.48698607e-01,\n",
       "        -2.60899693e-01, -2.34975681e-01, -2.39216879e-01,\n",
       "        -9.31912899e-01, -3.10815006e-01,  9.50177133e-01,\n",
       "        -6.49175122e-02, -4.55695838e-01,  4.75810379e-01,\n",
       "        -1.49177432e-01, -3.86637896e-01,  8.12791467e-01,\n",
       "         4.09931362e-01,  3.17654639e-01, -1.20774239e-01,\n",
       "         3.41932893e-01, -1.89940795e-01,  4.54021901e-01,\n",
       "        -8.18543673e-01,  9.05417502e-02,  3.93997699e-01,\n",
       "        -1.73369184e-01, -1.63284570e-01, -9.86287951e-01,\n",
       "        -2.10798696e-01,  3.85275751e-01,  9.89541352e-01,\n",
       "         6.87027097e-01,  1.88748449e-01,  5.42128861e-01,\n",
       "        -2.05668345e-01,  5.32564104e-01, -9.50126886e-01,\n",
       "         9.85420644e-01, -1.04703709e-01,  1.89262778e-01,\n",
       "         3.83954346e-02, -9.27603170e-02, -9.10461068e-01,\n",
       "        -2.66598374e-01,  8.06440234e-01, -5.06133139e-01,\n",
       "        -8.67905319e-01,  6.41448200e-02, -3.94841582e-01,\n",
       "        -2.81659812e-01, -2.21960276e-01,  5.77919602e-01,\n",
       "        -2.20285848e-01, -2.61983275e-01,  9.42845494e-02,\n",
       "         9.28999782e-01,  9.70288873e-01,  8.34843814e-01,\n",
       "        -3.55118394e-01,  5.09108663e-01, -9.01094973e-01,\n",
       "        -4.46625650e-01,  1.49512827e-01,  1.32540971e-01,\n",
       "         1.26522481e-01,  9.95017052e-01, -2.10155576e-01,\n",
       "        -2.17616409e-02, -9.49718595e-01, -9.89359796e-01,\n",
       "        -1.54727146e-01, -9.24037099e-01,  1.51259834e-02,\n",
       "        -6.06105328e-01,  4.39708471e-01,  3.93470973e-01,\n",
       "         8.18249490e-03,  3.80081594e-01, -9.85489666e-01,\n",
       "        -8.27497303e-01,  3.93761218e-01, -3.58864456e-01,\n",
       "         3.97692591e-01, -2.65368462e-01,  7.71100640e-01,\n",
       "         5.84995210e-01, -5.79721510e-01,  7.93668330e-01,\n",
       "         8.72235239e-01, -1.98634952e-01, -7.18157113e-01,\n",
       "         8.19811583e-01, -2.19876185e-01,  9.02986228e-01,\n",
       "        -5.89088857e-01,  9.87715065e-01,  5.89568973e-01,\n",
       "         7.38995075e-01, -9.43293750e-01, -1.43657371e-01,\n",
       "        -9.07122016e-01, -2.92420715e-01, -1.84518956e-02,\n",
       "        -4.84771609e-01,  4.23927426e-01,  5.50146043e-01,\n",
       "         2.73800880e-01,  8.03518116e-01, -5.51838338e-01,\n",
       "         9.97509122e-01, -8.32166731e-01, -9.59854245e-01,\n",
       "         1.33721277e-01, -1.39664248e-01, -9.91919041e-01,\n",
       "         5.21529615e-01,  1.37479708e-01, -2.94383377e-01,\n",
       "        -3.49178255e-01, -4.86975253e-01, -9.74039137e-01,\n",
       "         8.96468401e-01,  1.02732154e-02,  9.82121468e-01,\n",
       "        -2.22118031e-02, -9.21800673e-01, -4.87646610e-01,\n",
       "        -9.15354252e-01, -2.30934963e-01, -1.32328376e-01,\n",
       "         3.38342488e-01, -2.64811188e-01, -9.62030828e-01,\n",
       "         4.47255641e-01,  5.52259743e-01,  4.49940562e-01,\n",
       "        -8.57720822e-02,  9.97384667e-01,  9.99967575e-01,\n",
       "         9.81214941e-01,  8.79790187e-01,  9.09346163e-01,\n",
       "        -9.87534642e-01, -2.28363872e-01,  9.99986410e-01,\n",
       "        -9.42576110e-01, -1.00000000e+00, -9.45991397e-01,\n",
       "        -6.09244347e-01,  3.18173289e-01, -1.00000000e+00,\n",
       "        -6.43793717e-02,  1.15209132e-01, -9.31836545e-01,\n",
       "         1.16092227e-01,  9.82122183e-01,  9.91736293e-01,\n",
       "        -1.00000000e+00,  8.61364603e-01,  9.40673053e-01,\n",
       "        -6.24687910e-01,  8.01945984e-01, -2.52621680e-01,\n",
       "         9.78605449e-01,  3.47541928e-01,  3.11027139e-01,\n",
       "        -1.43925548e-01,  2.94055700e-01, -5.70959866e-01,\n",
       "        -8.57181966e-01,  4.16795462e-02, -7.62080848e-02,\n",
       "         9.30229604e-01,  1.01450436e-01, -6.98365569e-01,\n",
       "        -9.25473809e-01,  3.27895015e-01, -6.53703883e-02,\n",
       "        -2.83268899e-01, -9.63197470e-01, -8.75107944e-02,\n",
       "         9.18450207e-02,  7.88792670e-01, -2.26597749e-02,\n",
       "         2.01327756e-01, -7.82776594e-01,  1.23878866e-01,\n",
       "        -6.78919613e-01,  3.67868245e-01,  6.54397249e-01,\n",
       "        -9.38205659e-01, -6.43258452e-01,  1.61131740e-01,\n",
       "        -3.26464325e-01, -3.27052213e-02, -9.43404913e-01,\n",
       "         9.68227267e-01, -2.30849892e-01,  5.94202220e-01,\n",
       "         1.00000000e+00,  7.23341405e-02, -8.97215962e-01,\n",
       "         3.54551286e-01,  1.94186270e-01, -2.59770215e-01,\n",
       "         1.00000000e+00,  6.31834686e-01, -9.80033398e-01,\n",
       "        -5.21793306e-01,  3.41257811e-01, -4.46291357e-01,\n",
       "        -4.56279308e-01,  9.99120235e-01, -1.35382876e-01,\n",
       "        -2.39400808e-02,  1.66493580e-01,  9.76449788e-01,\n",
       "        -9.91789222e-01,  8.49006355e-01, -9.26576376e-01,\n",
       "        -9.73390460e-01,  9.69652355e-01,  9.43698466e-01,\n",
       "        -3.39658737e-01, -6.72217667e-01, -9.76309087e-03,\n",
       "        -1.79262042e-01,  2.04072773e-01, -9.65098798e-01,\n",
       "         7.20297337e-01,  4.54442084e-01, -1.01177894e-01,\n",
       "         9.16018426e-01, -8.66230845e-01, -5.39757371e-01,\n",
       "         2.92032629e-01, -1.10427789e-01,  2.56257027e-01,\n",
       "         5.38118124e-01,  4.43881482e-01, -2.13693976e-01,\n",
       "        -2.92080939e-02, -1.94266900e-01, -5.65131724e-01,\n",
       "        -9.72338140e-01,  1.18794486e-01,  1.00000000e+00,\n",
       "        -1.25060454e-02,  1.92387849e-01, -3.11955363e-01,\n",
       "         7.84880817e-02, -3.76040250e-01,  3.77223492e-01,\n",
       "         4.01438445e-01, -2.86802590e-01, -8.47041726e-01,\n",
       "         3.83396924e-01, -9.58282113e-01, -9.89288032e-01,\n",
       "         6.96353912e-01,  6.92483857e-02, -1.57327622e-01,\n",
       "         9.99945104e-01,  3.58505517e-01,  1.08087055e-01,\n",
       "        -2.81615276e-02,  8.53968322e-01, -1.04534365e-01,\n",
       "         4.87797320e-01,  1.52550027e-01,  9.80062783e-01,\n",
       "        -1.83690101e-01,  5.46442211e-01,  8.49535763e-01,\n",
       "        -4.43360835e-01, -2.76102334e-01, -6.22093022e-01,\n",
       "        -5.49724437e-02, -9.28658605e-01,  1.05628684e-01,\n",
       "        -9.66584802e-01,  9.59301353e-01,  5.43576479e-01,\n",
       "         3.04955721e-01,  3.92119437e-02,  1.48334593e-01,\n",
       "         1.00000000e+00, -2.64325291e-01,  5.18076122e-01,\n",
       "        -4.53999370e-01,  8.40336204e-01, -9.81685281e-01,\n",
       "        -8.10647726e-01, -3.74287575e-01,  5.19592762e-02,\n",
       "        -1.85671896e-01, -2.60550618e-01,  1.15392670e-01,\n",
       "        -9.71038580e-01,  2.26566747e-01,  2.79216617e-01,\n",
       "        -9.80975509e-01, -9.92789030e-01,  2.60119081e-01,\n",
       "         7.81510830e-01,  1.90499276e-02, -7.85452306e-01,\n",
       "        -7.01347053e-01, -5.69752276e-01,  5.52785575e-01,\n",
       "        -1.76281959e-01, -9.52425182e-01,  4.06893671e-01,\n",
       "        -1.42583728e-01,  4.15429503e-01, -1.35151252e-01,\n",
       "         5.82881391e-01,  1.57917097e-01,  7.93472528e-01,\n",
       "         9.92695540e-02,  7.20638186e-02,  8.33897889e-02,\n",
       "        -7.92223692e-01,  8.39538872e-01, -8.22585166e-01,\n",
       "        -6.03403509e-01, -5.07362979e-03,  1.00000000e+00,\n",
       "        -4.66169447e-01,  5.26995778e-01,  7.22811162e-01,\n",
       "         7.32706904e-01, -1.12735093e-01,  1.50623903e-01,\n",
       "         4.26397502e-01,  1.81335151e-01, -1.04042262e-01,\n",
       "        -2.88367182e-01, -7.30438590e-01, -2.69313365e-01,\n",
       "         5.58249891e-01, -1.37245625e-01, -6.44945279e-02,\n",
       "         8.09451997e-01,  3.49309713e-01,  1.10454544e-01,\n",
       "         1.58232659e-01, -9.98538211e-02,  9.99265432e-01,\n",
       "        -1.85935751e-01, -1.97304890e-01, -5.02058685e-01,\n",
       "         3.54187340e-02, -2.82546073e-01, -4.13454741e-01,\n",
       "         1.00000000e+00,  2.92447507e-01,  6.12233877e-02,\n",
       "        -9.93634224e-01, -4.04542685e-01, -9.10287797e-01,\n",
       "         9.99898911e-01,  8.25401425e-01, -8.64052832e-01,\n",
       "         6.39472842e-01,  5.08119643e-01, -1.58346724e-02,\n",
       "         8.24432790e-01, -1.12570934e-01, -8.73603746e-02,\n",
       "         1.06220424e-01, -3.44872177e-02,  9.72745836e-01,\n",
       "        -3.90707672e-01, -9.70306635e-01, -5.04161775e-01,\n",
       "         3.73773754e-01, -9.68964458e-01,  9.89342570e-01,\n",
       "        -4.65281337e-01, -1.98911622e-01, -3.06276083e-01,\n",
       "         4.18960005e-02,  6.10339582e-01, -5.34144789e-02,\n",
       "        -9.84635651e-01, -1.35745674e-01,  6.36917800e-02,\n",
       "         9.73755300e-01,  9.90050659e-02, -5.71445882e-01,\n",
       "        -8.77810299e-01,  4.34103422e-02,  3.70904028e-01,\n",
       "        -4.81344700e-01, -9.38052654e-01,  9.76629317e-01,\n",
       "        -9.81411934e-01,  5.97442925e-01,  1.00000000e+00,\n",
       "         2.74783731e-01, -5.16871274e-01,  1.42165720e-01,\n",
       "        -4.94351953e-01,  2.27908358e-01,  1.59852087e-01,\n",
       "         6.06818736e-01, -9.63133574e-01, -2.23805815e-01,\n",
       "        -6.61510453e-02,  2.42005378e-01, -6.99341372e-02,\n",
       "        -1.38938352e-01,  6.58608079e-01,  5.59413694e-02,\n",
       "        -5.38585722e-01, -5.36542654e-01, -1.29893310e-02,\n",
       "         3.77176642e-01,  8.40838909e-01, -1.73734158e-01,\n",
       "        -3.25094126e-02,  6.22567236e-02, -1.13219701e-01,\n",
       "        -9.19489264e-01, -2.25666702e-01, -2.54511714e-01,\n",
       "        -9.98512268e-01,  5.66545665e-01, -1.00000000e+00,\n",
       "        -5.25737777e-02, -3.70829791e-01, -2.04482257e-01,\n",
       "         8.06041598e-01,  3.45836043e-01,  2.35239089e-01,\n",
       "        -7.48552561e-01, -7.94944018e-02,  7.84033895e-01,\n",
       "         7.79044986e-01, -1.90319896e-01, -1.26978204e-01,\n",
       "        -7.28135288e-01,  1.82359040e-01, -1.86709594e-02,\n",
       "         2.04522163e-01, -1.90096065e-01,  7.13827372e-01,\n",
       "        -8.20701495e-02,  1.00000000e+00, -8.05396773e-03,\n",
       "        -6.71123862e-01, -9.73432660e-01,  1.21588998e-01,\n",
       "        -1.95875332e-01,  9.99991596e-01, -9.14346814e-01,\n",
       "        -9.54348028e-01,  2.85141826e-01, -4.65343416e-01,\n",
       "        -8.13540876e-01,  1.64710298e-01, -1.06504627e-01,\n",
       "        -6.83334172e-01, -7.01210618e-01,  9.47888732e-01,\n",
       "         8.70162427e-01, -5.45988560e-01,  5.48380673e-01,\n",
       "        -1.87785730e-01, -4.54315454e-01, -9.63670388e-02,\n",
       "         1.30979180e-01,  9.88398790e-01,  1.53188199e-01,\n",
       "         9.22119141e-01,  1.94257468e-01, -1.73918307e-01,\n",
       "         9.69472229e-01,  1.97972715e-01,  6.19976997e-01,\n",
       "         5.02538309e-02,  1.00000000e+00,  2.52911508e-01,\n",
       "        -9.21919405e-01,  2.03411102e-01, -9.85741198e-01,\n",
       "        -1.10465862e-01, -9.52746689e-01,  2.54833341e-01,\n",
       "         5.57825901e-02,  9.19611156e-01, -1.10679731e-01,\n",
       "         9.71532166e-01, -2.32007787e-01, -1.91967674e-02,\n",
       "        -2.51056492e-01,  1.54555202e-01,  3.43997359e-01,\n",
       "        -9.28600848e-01, -9.88017857e-01, -9.89780545e-01,\n",
       "         3.62201244e-01, -3.86807621e-01,  6.54153228e-02,\n",
       "         1.83926091e-01,  9.66849104e-02,  2.73069829e-01,\n",
       "         3.00490022e-01, -1.00000000e+00,  9.34709132e-01,\n",
       "         3.85811478e-01,  3.02824914e-01,  9.73944187e-01,\n",
       "         5.19434571e-01,  3.71019363e-01,  1.67992204e-01,\n",
       "        -9.88688827e-01, -9.75310862e-01, -2.14918673e-01,\n",
       "        -2.01103166e-01,  7.70611227e-01,  6.02130532e-01,\n",
       "         8.79255652e-01,  3.80162925e-01, -4.07553285e-01,\n",
       "        -2.16782376e-01,  1.25269800e-01, -6.95839047e-01,\n",
       "        -9.92438197e-01,  3.31737071e-01, -2.59126220e-02,\n",
       "        -9.72098529e-01,  9.63367224e-01, -6.16288245e-01,\n",
       "        -1.32892773e-01,  4.35115933e-01, -1.56718299e-01,\n",
       "         9.13231671e-01,  7.67546356e-01,  4.51184183e-01,\n",
       "         3.71156656e-03,  4.03758734e-01,  9.19267476e-01,\n",
       "         9.52199876e-01,  9.89371896e-01, -4.20735210e-01,\n",
       "         7.76322603e-01, -2.43368417e-01,  3.76209527e-01,\n",
       "         6.13343418e-01, -9.15033460e-01,  1.89766455e-02,\n",
       "         1.60110265e-01, -1.09482028e-01,  2.14879930e-01,\n",
       "        -1.35845572e-01, -9.64347661e-01,  5.13371766e-01,\n",
       "        -1.66134059e-01,  4.29995418e-01, -3.68751466e-01,\n",
       "         1.68638885e-01, -2.99175650e-01, -1.09358832e-01,\n",
       "        -7.20554173e-01, -5.44060051e-01,  6.18035972e-01,\n",
       "         3.21013212e-01,  9.09888625e-01,  5.08029222e-01,\n",
       "         7.10902140e-02, -7.37034857e-01, -1.15677968e-01,\n",
       "        -1.12609386e-01, -9.20794487e-01,  9.29902196e-01,\n",
       "        -1.46306576e-02,  2.83209831e-01,  6.62679672e-02,\n",
       "        -1.06557928e-01,  7.49155939e-01, -2.27476016e-01,\n",
       "        -3.54881525e-01, -2.64606565e-01, -7.28504360e-01,\n",
       "         9.06443000e-01, -3.57667029e-01, -4.21099484e-01,\n",
       "        -4.48478311e-01,  6.40797794e-01,  2.15343326e-01,\n",
       "         9.97547925e-01, -2.39570841e-01, -5.41228354e-01,\n",
       "        -2.26100072e-01, -2.12070465e-01,  3.41614962e-01,\n",
       "        -3.28123778e-01, -1.00000000e+00,  3.46563727e-01,\n",
       "         6.05382845e-02,  2.92154819e-01, -3.34163785e-01,\n",
       "         2.59417385e-01, -2.69307315e-01, -9.75235999e-01,\n",
       "        -8.13412070e-02,  2.18596175e-01, -4.08782884e-02,\n",
       "        -4.61665988e-01, -5.18242598e-01,  5.64232349e-01,\n",
       "         1.42871082e-01,  7.93668330e-01,  8.95387053e-01,\n",
       "         1.38134673e-01,  5.47312498e-01,  6.39439166e-01,\n",
       "         5.99300824e-02, -6.52330458e-01,  9.21658933e-01]], dtype=float32)>, past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(blue)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
